# Chapter2
Chapter 2: Training Simple Machine Learning Algorithms for Classification


## Artificial neurons â€“ a brief glimpse into the early history of machine learning 
> ![image](https://user-images.githubusercontent.com/63633387/190891701-d296950e-5e27-4109-83a8-b66aeb5fd0e6.png)
> 
> ìƒë¬¼í•™ì  ë‰´ëŸ°ì€ í™”í•™ì , ì „ê¸°ì  ì‹ í˜¸ì˜ ì²˜ë¦¬ì™€ ì „ë‹¬ì— ê´€ì—¬í•˜ëŠ” ë‡Œì˜ ìƒí˜¸ ì—°ê²°ëœ ì‹ ê²½ ì„¸í¬
>  
> McCulloch ì™€ PittsëŠ” ì´ëŸ¬í•œ ì‹ ê²½ì„¸í¬ë¥¼ ì´ì§„ ì¶œë ¥ì„ ê°–ëŠ” ë‹¨ìˆœí•œ ë…¼ë¦¬ ê²Œì´íŠ¸ë¼ê³  ì„¤ëª…
> ì—¬ëŸ¬ ì‹ í˜¸ê°€ ê°€ì§€ëŒê¸°ì— ë„ë‹¬í•œ ë‹¤ìŒ ì„¸í¬ ë³¸ì²´ì— í†µí•©ë˜ê³ , ì¶•ì ëœ ì‹ í˜¸ê°€ íŠ¹ì • ìž„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ì¶•ì‚­ì— ì˜í•´ ì „ë‹¬ë  ì¶œë ¥ ì‹ í˜¸ê°€ ìƒì„±  

#### The formal definition of an artificial neuron  
> 
> ì¸ê³µ ë‰´ëŸ°ì˜ ì•„ì´ë””ì–´ë¥¼ 0ê³¼ 1ì˜ ë‘ ê°€ì§€ í´ëž˜ìŠ¤ê°€ ìžˆëŠ” ì´ì§„ ë¶„ë¥˜ì— ì ìš©  
> ê²°ì • í•¨ìˆ˜ $ðœŽ(z)$ëŠ” íŠ¹ì • ìž…ë ¥ ê°’ $x$ì™€ í•´ë‹¹ ê°€ì¤‘ì¹˜ ë²¡í„° $w$ì˜ ì„ í˜• ì¡°í•©  
> $z$ëŠ” $w_1x_1 + w_2x_2 + \cdots + w_mx_m$ ì´ë‹¤.  
>   
> íŠ¹ì • ìž…ë ¥ê°’ $x_i$ê°€ ì •í•´ì§„ ìž„ê³„ì¹˜ $ðœƒ$ë³´ë‹¤ í¬ë©´ 1 ì•„ë‹ˆë©´ 0ìœ¼ë¡œ ë¶„ë¥˜í•˜ë©°  
> í¼ì…‰íŠ¸ë¡  ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì •ì˜ëœ ê²°ì • í•¨ìˆ˜ $ðœŽ(âˆ™)$ëŠ” ë‹¨ìœ„ ê³„ë‹¨ í•¨ìˆ˜(ì•„ëž˜ ê·¸ë¦¼ì˜ ì™¼ìª½í˜•íƒœì˜ í•¨ìˆ˜ë¥¼ ë‹¨ìœ„ê³„ë‹¨ í•¨ìˆ˜ë¼ê³  í•¨)ì˜ ë³€í˜•ì´ë‹¤. 
>   
> $$ðœŽ(z) = 
> \begin{cases} 
> 1\ if\ z\geq0\\ 
> 0\ otherwise 
> \end{cases}$$
>   
> ![image](https://user-images.githubusercontent.com/63633387/190891854-a2673e88-8862-49ff-8146-853c02806173.png)
>   
> ìž…ë ¥ $z = w^Tx + b$ê°€ í¼ì…‰íŠ¸ë¡ ì˜ ê²°ì • í•¨ìˆ˜ì— ì˜í•´ ì´ì§„ ì¶œë ¥(0 ë˜ëŠ” 1)ì´ ë°©ë²•ê³¼ ì„ í˜• ê²°ì • ê²½ê³„ì— ì˜í•´ ë¶„ë¦¬ë  ìˆ˜ ìžˆëŠ” ë‘ ê°€ì§€ í´ëž˜ìŠ¤ë¡œ êµ¬ë³„í•˜ëŠ” ë°©ë²•
#### The perceptron learning rule  
>   
> Rosenblattâ€™s ê³ ì „ì ì¸ í¼ì…‰íŠ¸ë¡  ê·œì¹™ì€ ë§¤ìš° ê°„ë‹¨í•˜ë©° í¼ì…‰íŠ¸ë¡  ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ì™€ ê°™ë‹¤.
>   
> 1. ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ë¥¼ 0 ë˜ëŠ” ìž‘ì€ ìˆ˜ì˜ ë‚œìˆ˜ë¡œ ì´ˆê¸°í™”
> 2. ê° ì˜ˆì‹œ $x^(i)$ë¥¼ í•™ìŠµ  
>   a. ì¶œë ¥ê°’ $\widehat{y}^(i)$ ê³„ì‚°  
>   b. ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ ë‹¨ìœ„ ì—…ë°ì´íŠ¸
>   
>   
> ![image](https://user-images.githubusercontent.com/63633387/190893585-87889d00-173d-4bf3-9108-f974ee6977b3.png)
>   
>   
> ë‘ í´ëž˜ìŠ¤ê°€ ì„ í˜• ê²°ì • ê²½ê³„ë¡œ ë¶„ë¦¬ë  ìˆ˜ ì—†ëŠ” ê²½ìš°,  
> í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸(ì—í¬í¬)ì— ëŒ€í•œ ìµœëŒ€ í—ˆìš© íšŸìˆ˜ ë°/ë˜ëŠ” í—ˆìš©ë˜ëŠ” ìž˜ëª» ë¶„ë¥˜ëœ ìž…ë ¥ì˜ ê°œìˆ˜ì— ëŒ€í•œ ìž„ê³„ê°’ì„ ì„¤ì •í•  ìˆ˜ ìžˆë‹¤.  
> ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ í¼ì…‰íŠ¸ë¡ ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ë©ˆì¶”ì§€ ì•Šì„ ê²ƒ  
>   
>   
> ![image](https://user-images.githubusercontent.com/63633387/190893602-f7bcd2f4-e57b-4a8d-a5d1-952b2cf684ed.png)
>   
>   
## Implementing a perceptron learning algorithm in Python (í•´ë‹¹ íŒŒì´ì¬ ì½”ë“œëŠ” [ì—¬ê¸°](https://github.com/ww232330/AI_study/blob/main/Chapter2/Chapter_2_Training_Simple_Machine_Learning_Algorithms_for_Classification.ipynb)ì— ìžˆìŒ)
#### An object-oriented perceptron API  
#### Training a perceptron model on the Iris dataset  
## Adaptive linear neurons and the convergence of learning 
>   
> ![image](https://user-images.githubusercontent.com/63633387/190893789-641655f9-d2bc-483f-8508-9ef6f84c16aa.png)
>   
#### Minimizing loss functions with gradient descent  
>   
> ê²°ê³¼ì™€ ì‹¤ì œ ê°’ì˜ mean squared error (MSE)ë¥¼ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•œë‹¤.
> $$\frac{1}{2n} \displaystyle\sum{(y^(i)-\widehat{y}^(i))^2}$$
>   
#### Implementing Adaline in Python  
#### Improving gradient descent through feature scaling  
#### Large-scale machine learning and stochastic gradient descent  
## Summary 
