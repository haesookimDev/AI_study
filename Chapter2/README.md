# Chapter2
Chapter 2: Training Simple Machine Learning Algorithms for Classification


## Artificial neurons â€“ a brief glimpse into the early history of machine learning 
> ![image](https://user-images.githubusercontent.com/63633387/190891701-d296950e-5e27-4109-83a8-b66aeb5fd0e6.png)
> 
> ìƒë¬¼í•™ì  ë‰´ëŸ°ì€ í™”í•™ì , ì „ê¸°ì  ì‹ í˜¸ì˜ ì²˜ë¦¬ì™€ ì „ë‹¬ì— ê´€ì—¬í•˜ëŠ” ë‡Œì˜ ìƒí˜¸ ì—°ê²°ëœ ì‹ ê²½ ì„¸í¬
>  
> McCulloch ì™€ PittsëŠ” ì´ëŸ¬í•œ ì‹ ê²½ì„¸í¬ë¥¼ ì´ì§„ ì¶œë ¥ì„ ê°–ëŠ” ë‹¨ìˆœí•œ ë…¼ë¦¬ ê²Œì´íŠ¸ë¼ê³  ì„¤ëª…
> ì—¬ëŸ¬ ì‹ í˜¸ê°€ ê°€ì§€ëŒê¸°ì— ë„ë‹¬í•œ ë‹¤ìŒ ì„¸í¬ ë³¸ì²´ì— í†µí•©ë˜ê³ , ì¶•ì ëœ ì‹ í˜¸ê°€ íŠ¹ì • ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ì¶•ì‚­ì— ì˜í•´ ì „ë‹¬ë  ì¶œë ¥ ì‹ í˜¸ê°€ ìƒì„±  

#### The formal definition of an artificial neuron  
> 
> ì¸ê³µ ë‰´ëŸ°ì˜ ì•„ì´ë””ì–´ë¥¼ 0ê³¼ 1ì˜ ë‘ ê°€ì§€ í´ë˜ìŠ¤ê°€ ìˆëŠ” ì´ì§„ ë¶„ë¥˜ì— ì ìš©  
> ê²°ì • í•¨ìˆ˜ $ğœ(z)$ëŠ” íŠ¹ì • ì…ë ¥ ê°’ $x$ì™€ í•´ë‹¹ ê°€ì¤‘ì¹˜ ë²¡í„° $w$ì˜ ì„ í˜• ì¡°í•©  
> $z$ëŠ” $w_1x_1 + w_2x_2 + ... + w_mx_m$ ì´ë‹¤.  
>   
> íŠ¹ì • ì…ë ¥ê°’ $x_i$ê°€ ì •í•´ì§„ ì„ê³„ì¹˜ $ğœƒ$ë³´ë‹¤ í¬ë©´ 1 ì•„ë‹ˆë©´ 0ìœ¼ë¡œ ë¶„ë¥˜í•˜ë©°  
> í¼ì…‰íŠ¸ë¡  ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì •ì˜ëœ ê²°ì • í•¨ìˆ˜ $ğœ(âˆ™)$ëŠ” ë‹¨ìœ„ ê³„ë‹¨ í•¨ìˆ˜(ì•„ë˜ ê·¸ë¦¼ì˜ ì™¼ìª½í˜•íƒœì˜ í•¨ìˆ˜ë¥¼ ë‹¨ìœ„ê³„ë‹¨ í•¨ìˆ˜ë¼ê³  í•¨)ì˜ ë³€í˜•ì´ë‹¤. 
>   
> $$ğœ(z) = 
> \begin{cases} 
> 1\;if\;z\geq0\\ 
> 0\;otherwise 
> \end{cases}$$
>   
> ![image](https://user-images.githubusercontent.com/63633387/190891854-a2673e88-8862-49ff-8146-853c02806173.png)
>   
> ì…ë ¥ $z = w^Tx + b$ê°€ í¼ì…‰íŠ¸ë¡ ì˜ ê²°ì • í•¨ìˆ˜ì— ì˜í•´ ì´ì§„ ì¶œë ¥(0 ë˜ëŠ” 1)ì´ ë°©ë²•ê³¼ ì„ í˜• ê²°ì • ê²½ê³„ì— ì˜í•´ ë¶„ë¦¬ë  ìˆ˜ ìˆëŠ” ë‘ ê°€ì§€ í´ë˜ìŠ¤ë¡œ êµ¬ë³„í•˜ëŠ” ë°©ë²•
#### The perceptron learning rule  
## Implementing a perceptron learning algorithm in Python
#### An object-oriented perceptron API  
#### Training a perceptron model on the Iris dataset  
## Adaptive linear neurons and the convergence of learning 
#### Minimizing loss functions with gradient descent  
#### Implementing Adaline in Python  
#### Improving gradient descent through feature scaling  
#### Large-scale machine learning and stochastic gradient descent  
## Summary 
