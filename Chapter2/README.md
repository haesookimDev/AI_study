# Chapter2
Chapter 2: Training Simple Machine Learning Algorithms for Classification


## Artificial neurons – a brief glimpse into the early history of machine learning 
![image](https://user-images.githubusercontent.com/63633387/190891701-d296950e-5e27-4109-83a8-b66aeb5fd0e6.png)
> 생물학적 뉴런은 화학적, 전기적 신호의 처리와 전달에 관여하는 뇌의 상호 연결된 신경 세포
>  
> McCulloch 와 Pitts는 이러한 신경세포를 이진 출력을 갖는 단순한 논리 게이트라고 설명
> 여러 신호가 가지돌기에 도달한 다음 세포 본체에 통합되고, 축적된 신호가 특정 임계값을 초과하면 축삭에 의해 전달될 출력 신호가 생성  

#### The formal definition of an artificial neuron  

#### The perceptron learning rule  
## Implementing a perceptron learning algorithm in Python
#### An object-oriented perceptron API  
#### Training a perceptron model on the Iris dataset  
## Adaptive linear neurons and the convergence of learning 
#### Minimizing loss functions with gradient descent  
#### Implementing Adaline in Python  
#### Improving gradient descent through feature scaling  
#### Large-scale machine learning and stochastic gradient descent  
## Summary 
